{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Ethics Researchers\n",
    "\n",
    "This script creates a search query for Scopus using the IDs of authors who have published at either FAccT or AIES based on bibliographic data from Scopus. It serves as an alternative to the API search capability\n",
    "\n",
    "+ **Input data:** Scopus metadata in csv format  \n",
    "+ **Output data:** Search query in txt file for Scopus advanced search function\n",
    "\n",
    "Developed by Tyler Reinmund  \n",
    "Date: 8 June 2021\n",
    "\n",
    "Department of Science and Technology Studies  \n",
    "University College London"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import glob\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(449, 452)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Scopus data: FAccT and AIES publications\n",
    "in_path = '' #Update file path here\n",
    "all_files = glob.glob(in_path + \"/*.csv\")\n",
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    li.append(df)\n",
    "\n",
    "full_df = pd.concat(li, axis=0, ignore_index=True, sort=False)\n",
    "\n",
    "full_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(364, 452)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop articles without abstracts, titles, keywords, authors, or author ID\n",
    "df_clean = full_df.dropna(axis=0, subset=['Abstract', 'Title', 'Author Keywords', 'Authors', 'Author(s) ID'])\n",
    "\n",
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "996"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create list of author IDs from \"Author(s) ID\" column\n",
    "id_list = df_clean['Author(s) ID'].to_list()\n",
    "\n",
    "# Concatenate articles\n",
    "id_list = ''.join(id_list)\n",
    "\n",
    "# Split each author ID into separate string\n",
    "id_list = id_list.split(';')\n",
    "\n",
    "# Remove duplicates\n",
    "id_list = list(set(id_list))\n",
    "\n",
    "# Remove any invalid entries\n",
    "id_list = [x for x in id_list if x.isdigit()]\n",
    "\n",
    "len(id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create search query for Scopus search\n",
    "id_search = ['AU-ID({}) OR '.format(s) for s in id_list] #List comprehension to include search terms for author ID 'AU-ID(string) OR '\n",
    "\n",
    "# Concatenate all items into strings with 50 author IDs each for search\n",
    "n = 50\n",
    "\n",
    "# List comprehension to break list into sublists with 50 elements each\n",
    "id_separated = [id_search[i * n:(i + 1) * n] for i in range((len(id_search) + n - 1) // n)]\n",
    "\n",
    "# For loop to save each element as a string file\n",
    "out_path = '' # Update file path here to save search strings\n",
    "\n",
    "for i in range(len(id_separated)):\n",
    "    name = 'auth_id_search_{}'.format(i)\n",
    "    filename = '%s.txt' % name\n",
    "    sub_list = ''.join(id_separated[i])\n",
    "    sub_list = sub_list[:-4:]\n",
    "    print(sub_list, file=open(os.path.join(out_path, filename), 'w'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
